{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 04: Subsampling and Preparation for Modeling\n",
    "#\n",
    "# This notebook prepares synthetic datasets (manual, copula, CTGAN) for modeling by:\n",
    "# - Subsampling each to match the exact number of defaults and non-defaults in the Home Credit dataset (~8% default rate).\n",
    "# - Aligning variable columns across all datasets.\n",
    "# - Exporting ready-to-model merged (Home Credit + synthetic footprint variables) and separate datasets.\n",
    "#\n",
    "# **Key Notes:**\n",
    "# - The Home Credit dataset has a default rate of ~8%, higher than Berg et al. (~0.9%).\n",
    "# - Subsampling ensures exact matches for default/non-default counts for fair modeling comparisons.\n",
    "# - Random seeds are set for reproducibility.\n",
    "# - All datasets are validated for shape, column consistency, and default rates after each major step.\n",
    "# - File paths are kept as provided, assuming they are correct in your environment.\n",
    "# - Error handling and validation checks ensure robustness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Load and Standardize Datasets\n",
    "#\n",
    "# Load the Home Credit and synthetic datasets, standardize the target column to 'TARGET', and validate dataset shapes and target column presence. Add error handling for file loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded homecredit from /home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed/home_credit_sample.csv\n",
      "Successfully loaded manual from /home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed/synthetic_digital_footprint_with_target.csv\n",
      "Successfully loaded copula from /home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed/synthetic_digital_footprint_copula.csv\n",
      "Successfully loaded ctgan from /home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed{synthetic_digital_footprint_ctgan.csv\n",
      "Home Credit: Target column standardized to 'TARGET'\n",
      "Manual: Target column standardized to 'TARGET'\n",
      "Copula: Target column standardized to 'TARGET'\n",
      "CTGAN: Target column standardized to 'TARGET'\n",
      "\n",
      "Dataset Shape Check:\n",
      "Home Credit: (10000, 34)\n",
      "Manual Synth: (100000, 18)\n",
      "Copula Synth: (100000, 18)\n",
      "CTGAN Synth: (100000, 18)\n",
      "\n",
      "Home Credit: 807 defaults, 9193 non-defaults, default rate: 8.07%\n",
      "Manual: 934 defaults, 99066 non-defaults\n",
      "Copula: 964 defaults, 99036 non-defaults\n",
      "CTGAN: 219 defaults, 99781 non-defaults\n",
      "⚠️ WARNING: Not enough samples in CTGAN synthetic dataset! Will sample with replacement.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define file paths (unchanged as per instruction)\n",
    "file_paths = {\n",
    "    \"homecredit\": \"/home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed/home_credit_sample.csv\",\n",
    "    \"manual\": \"/home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed/synthetic_digital_footprint_with_target.csv\",\n",
    "    \"copula\": \"/home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed/synthetic_digital_footprint_copula.csv\",\n",
    "    \"ctgan\": \"/home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed{synthetic_digital_footprint_ctgan.csv\"\n",
    "}\n",
    "\n",
    "# Load datasets with error handling\n",
    "datasets = {}\n",
    "for name, path in file_paths.items():\n",
    "    try:\n",
    "        datasets[name] = pd.read_csv(path)\n",
    "        print(f\"Successfully loaded {name} from {path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {name}: {e}\")\n",
    "        raise\n",
    "\n",
    "homecredit = datasets[\"homecredit\"]\n",
    "manual = datasets[\"manual\"]\n",
    "copula = datasets[\"copula\"]\n",
    "ctgan = datasets[\"ctgan\"]\n",
    "\n",
    "# Standardize target column to 'TARGET'\n",
    "for df, name in [(homecredit, \"Home Credit\"), (manual, \"Manual\"), (copula, \"Copula\"), (ctgan, \"CTGAN\")]:\n",
    "    if 'DEFAULT' in df.columns and 'TARGET' not in df.columns:\n",
    "        df.rename(columns={'DEFAULT': 'TARGET'}, inplace=True)\n",
    "    elif 'TARGET' not in df.columns:\n",
    "        raise ValueError(f\"Target column not found in {name} dataset\")\n",
    "    print(f\"{name}: Target column standardized to 'TARGET'\")\n",
    "\n",
    "# Initial shape and default count check\n",
    "n_total = len(homecredit)\n",
    "n_defaults = int(homecredit['TARGET'].sum())\n",
    "n_nondefaults = n_total - n_defaults\n",
    "expected_default_rate = n_defaults / n_total\n",
    "\n",
    "print(\"\\nDataset Shape Check:\")\n",
    "print(f\"Home Credit: {homecredit.shape}\")\n",
    "print(f\"Manual Synth: {manual.shape}\")\n",
    "print(f\"Copula Synth: {copula.shape}\")\n",
    "print(f\"CTGAN Synth: {ctgan.shape}\")\n",
    "print(f\"\\nHome Credit: {n_defaults} defaults, {n_nondefaults} non-defaults, default rate: {expected_default_rate:.2%}\")\n",
    "\n",
    "# Check available samples in synthetic datasets\n",
    "for label, df in [(\"Manual\", manual), (\"Copula\", copula), (\"CTGAN\", ctgan)]:\n",
    "    available_defaults = df[df['TARGET'] == 1].shape[0]\n",
    "    available_nondefaults = df[df['TARGET'] == 0].shape[0]\n",
    "    print(f\"{label}: {available_defaults} defaults, {available_nondefaults} non-defaults\")\n",
    "    if available_defaults < n_defaults or available_nondefaults < n_nondefaults:\n",
    "        print(f\"⚠️ WARNING: Not enough samples in {label} synthetic dataset! Will sample with replacement.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# %% [markdown]\n",
    "# ## Validate Default Rates\n",
    "#\n",
    "# Calculate and display the default rates for each dataset to ensure alignment with the Home Credit dataset's ~8% default rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Credit: 10000 rows, 807 defaults (8.07%)\n",
      "Manual Synthetic: 100000 rows, 934 defaults (0.93%)\n",
      "Copula Synthetic: 100000 rows, 964 defaults (0.96%)\n",
      "CTGAN Synthetic: 100000 rows, 219 defaults (0.22%)\n"
     ]
    }
   ],
   "source": [
    "def print_defaults(df, label):\n",
    "    n = len(df)\n",
    "    n_def = int(df['TARGET'].sum())\n",
    "    rate = n_def / n\n",
    "    print(f\"{label}: {n} rows, {n_def} defaults ({rate:.2%})\")\n",
    "\n",
    "print_defaults(homecredit, \"Home Credit\")\n",
    "print_defaults(manual, \"Manual Synthetic\")\n",
    "print_defaults(copula, \"Copula Synthetic\")\n",
    "print_defaults(ctgan, \"CTGAN Synthetic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample Each Dataset to 10,000 Rows, Stratified by TARGET\n",
    "\n",
    "- Maintains the default/non-default proportion\n",
    "- Repeats with replacement if not enough default rows in small synthetic sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling with replacement for CTGAN: defaults \n",
      "\n",
      "Subsampled Dataset Validation:\n",
      "Manual Subsampled: 10000 rows, 807 defaults (8.07%)\n",
      "Manual Shape: (10000, 18), Columns: ['age', 'order_amount', 'age_quintile', 'order_amount_quintile', 'credit_score_quintile']...\n",
      "Copula Subsampled: 10000 rows, 807 defaults (8.07%)\n",
      "Copula Shape: (10000, 18), Columns: ['credit_score_quintile', 'device_type', 'os', 'email_host', 'channel']...\n",
      "CTGAN Subsampled: 10000 rows, 807 defaults (8.07%)\n",
      "CTGAN Shape: (10000, 18), Columns: ['age', 'order_amount', 'age_quintile', 'order_amount_quintile', 'credit_score_quintile']...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "def exact_stratified(df, n_def, n_nondef, target_col='TARGET', random_state=42):\n",
    "    \"\"\"Subsample dataset to match exact default and non-default counts.\"\"\"\n",
    "    df_def = df[df[target_col] == 1]\n",
    "    df_nondef = df[df[target_col] == 0]\n",
    "    rep_def = n_def > len(df_def)\n",
    "    rep_nondef = n_nondef > len(df_nondef)\n",
    "    \n",
    "    # Log replacement usage\n",
    "    if rep_def or rep_nondef:\n",
    "        print(f\"Sampling with replacement for {label}: {rep_def and 'defaults' or ''} {rep_nondef and 'non-defaults' or ''}\")\n",
    "    \n",
    "    # Perform stratified sampling\n",
    "    sampled_def = resample(df_def, n_samples=n_def, replace=rep_def, random_state=random_state)\n",
    "    sampled_nondef = resample(df_nondef, n_samples=n_nondef, replace=rep_nondef, random_state=random_state)\n",
    "    result = pd.concat([sampled_def, sampled_nondef], axis=0).sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "    # Validate output\n",
    "    if len(result) != (n_def + n_nondef) or result[target_col].sum() != n_def:\n",
    "        raise ValueError(f\"Subsampling failed for {label}: Expected {n_def} defaults and {n_nondef} non-defaults, got {result[target_col].sum()} defaults and {len(result) - result[target_col].sum()} non-defaults\")\n",
    "    return result\n",
    "\n",
    "# Subsample synthetic datasets\n",
    "manual_matched = exact_stratified(manual, n_defaults, n_nondefaults, random_state=42)\n",
    "copula_matched = exact_stratified(copula, n_defaults, n_nondefaults, random_state=42)\n",
    "ctgan_matched = exact_stratified(ctgan, n_defaults, n_nondefaults, random_state=42)\n",
    "\n",
    "# Validate subsampled datasets\n",
    "print(\"\\nSubsampled Dataset Validation:\")\n",
    "for label, df in [(\"Manual\", manual_matched), (\"Copula\", copula_matched), (\"CTGAN\", ctgan_matched)]:\n",
    "    print_defaults(df, f\"{label} Subsampled\")\n",
    "    print(f\"{label} Shape: {df.shape}, Columns: {list(df.columns)[:5]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Footprint Variables\n",
    "#\n",
    "# Keep only the specified footprint variables and the target column for synthetic datasets. Rename the target to 'DEFAULT_SYNTH' to avoid column name conflicts during merging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Footprint Variables\n",
    "#\n",
    "# Keep only the specified footprint variables and the target column for synthetic datasets. Rename the target to 'DEFAULT_SYNTH' to avoid column name conflicts during merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Footprint Columns: ['device_type', 'os', 'email_host', 'channel', 'checkout_time', 'name_in_email', 'number_in_email', 'is_lowercase', 'email_error', 'DEFAULT_SYNTH']\n",
      "Copula Footprint Columns: ['device_type', 'os', 'email_host', 'channel', 'checkout_time', 'name_in_email', 'number_in_email', 'is_lowercase', 'email_error', 'DEFAULT_SYNTH']\n",
      "CTGAN Footprint Columns: ['device_type', 'os', 'email_host', 'channel', 'checkout_time', 'name_in_email', 'number_in_email', 'is_lowercase', 'email_error', 'DEFAULT_SYNTH']\n"
     ]
    }
   ],
   "source": [
    "# Define footprint variables\n",
    "footprint_vars = [\n",
    "    \"device_type\", \"os\", \"email_host\", \"channel\",\n",
    "    \"checkout_time\", \"name_in_email\", \"number_in_email\", \"is_lowercase\", \"email_error\"\n",
    "]\n",
    "\n",
    "# Validate footprint variables exist in synthetic datasets\n",
    "for label, df in [(\"Manual\", manual_matched), (\"Copula\", copula_matched), (\"CTGAN\", ctgan_matched)]:\n",
    "    missing_vars = [var for var in footprint_vars if var not in df.columns]\n",
    "    if missing_vars:\n",
    "        print(f\"⚠️ WARNING: {label} missing footprint variables: {missing_vars}. Consider regenerating dataset.\")\n",
    "\n",
    "# Keep only footprint variables and TARGET\n",
    "keep_cols = footprint_vars + ['TARGET']\n",
    "manual_fp = manual_matched[keep_cols].copy()\n",
    "copula_fp = copula_matched[keep_cols].copy()\n",
    "ctgan_fp = ctgan_matched[keep_cols].copy()\n",
    "\n",
    "# Rename TARGET to DEFAULT_SYNTH\n",
    "manual_fp = manual_fp.rename(columns={'TARGET': 'DEFAULT_SYNTH'})\n",
    "copula_fp = copula_fp.rename(columns={'TARGET': 'DEFAULT_SYNTH'})\n",
    "ctgan_fp = ctgan_fp.rename(columns={'TARGET': 'DEFAULT_SYNTH'})\n",
    "\n",
    "# Ensure no duplicate TARGET columns\n",
    "for df, label in [(manual_fp, \"Manual\"), (copula_fp, \"Copula\"), (ctgan_fp, \"CTGAN\")]:\n",
    "    if 'TARGET' in df.columns:\n",
    "        df.drop(columns='TARGET', inplace=True)\n",
    "    print(f\"{label} Footprint Columns: {list(df.columns)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Footprint Datasets\n",
    "#\n",
    "# Verify the columns in the footprint datasets to ensure correct renaming and column selection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual_fp Index(['device_type', 'os', 'email_host', 'channel', 'checkout_time',\n",
      "       'name_in_email', 'number_in_email', 'is_lowercase', 'email_error',\n",
      "       'DEFAULT_SYNTH'],\n",
      "      dtype='object')\n",
      "copula_fp Index(['device_type', 'os', 'email_host', 'channel', 'checkout_time',\n",
      "       'name_in_email', 'number_in_email', 'is_lowercase', 'email_error',\n",
      "       'DEFAULT_SYNTH'],\n",
      "      dtype='object')\n",
      "ctgan_fp Index(['device_type', 'os', 'email_host', 'channel', 'checkout_time',\n",
      "       'name_in_email', 'number_in_email', 'is_lowercase', 'email_error',\n",
      "       'DEFAULT_SYNTH'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"manual_fp\", manual_fp.columns    )\n",
    "print(\"copula_fp\", copula_fp.columns)\n",
    "print(\"ctgan_fp\", ctgan_fp.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Home Credit with Synthetic Footprint Datasets\n",
    "#\n",
    "# Merge the full Home Credit dataset (all columns) with each synthetic footprint dataset, aligning rows by TARGET/DEFAULT_SYNTH values. Validate row counts and default alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Dataset Validation:\n",
      "Manual Merged Shape: (10000, 44)\n",
      "Manual Merged Columns (first 5): ['home_EXT_SOURCE_1', 'home_EXT_SOURCE_2', 'home_EXT_SOURCE_3', 'home_AMT_CREDIT', 'home_AMT_ANNUITY']...\n",
      "Manual Merged Default Count: 807\n",
      "Copula Merged Shape: (10000, 44)\n",
      "Copula Merged Columns (first 5): ['home_EXT_SOURCE_1', 'home_EXT_SOURCE_2', 'home_EXT_SOURCE_3', 'home_AMT_CREDIT', 'home_AMT_ANNUITY']...\n",
      "Copula Merged Default Count: 807\n",
      "CTGAN Merged Shape: (10000, 44)\n",
      "CTGAN Merged Columns (first 5): ['home_EXT_SOURCE_1', 'home_EXT_SOURCE_2', 'home_EXT_SOURCE_3', 'home_AMT_CREDIT', 'home_AMT_ANNUITY']...\n",
      "CTGAN Merged Default Count: 807\n"
     ]
    }
   ],
   "source": [
    "def merge_by_target(home, synth, random_state=42):\n",
    "    \"\"\"Merge Home Credit (all columns) with synthetic footprint dataset by sorting on target columns.\"\"\"\n",
    "    # Validate input shapes and target counts\n",
    "    if len(home) != len(synth):\n",
    "        raise ValueError(f\"Row count mismatch: Home Credit ({len(home)}) vs Synthetic ({len(synth)})\")\n",
    "    if home['TARGET'].sum() != synth['DEFAULT_SYNTH'].sum():\n",
    "        raise ValueError(f\"Default count mismatch: Home Credit ({home['TARGET'].sum()}) vs Synthetic ({synth['DEFAULT_SYNTH'].sum()})\")\n",
    "    \n",
    "    # Sort by target columns\n",
    "    home_sorted = home.sort_values(\"TARGET\").reset_index(drop=True)\n",
    "    synth_sorted = synth.sort_values(\"DEFAULT_SYNTH\").reset_index(drop=True)\n",
    "    \n",
    "    # Merge side by side\n",
    "    merged = pd.concat([home_sorted, synth_sorted], axis=1, keys=['home', 'synth'])\n",
    "    merged.columns = [f\"{s}_{c}\" for s, c in merged.columns]\n",
    "    \n",
    "    # Validate merged dataset\n",
    "    if len(merged) != len(home):\n",
    "        raise ValueError(f\"Merged dataset row count ({len(merged)}) does not match input ({len(home)})\")\n",
    "    return merged\n",
    "\n",
    "# Perform merges\n",
    "merged_manual = merge_by_target(homecredit, manual_fp)\n",
    "merged_copula = merge_by_target(homecredit, copula_fp)\n",
    "merged_ctgan = merge_by_target(homecredit, ctgan_fp)\n",
    "\n",
    "# Validate merged datasets\n",
    "print(\"\\nMerged Dataset Validation:\")\n",
    "for label, df in [(\"Manual\", merged_manual), (\"Copula\", merged_copula), (\"CTGAN\", merged_ctgan)]:\n",
    "    print(f\"{label} Merged Shape: {df.shape}\")\n",
    "    print(f\"{label} Merged Columns (first 5): {list(df.columns)[:5]}...\")\n",
    "    print(f\"{label} Merged Default Count: {df['home_TARGET'].sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Subsampled and Merged Datasets\n",
    "#\n",
    "# Save all datasets to CSV files and verify successful writes by checking file existence and row counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved matched_manual_footprint.csv: 10000 rows, 10 columns\n",
      "Saved matched_copula_footprint.csv: 10000 rows, 10 columns\n",
      "Saved matched_ctgan_footprint.csv: 10000 rows, 10 columns\n",
      "Saved merged_homecredit_manual_fp.csv: 10000 rows, 44 columns\n",
      "Saved merged_homecredit_copula_fp.csv: 10000 rows, 44 columns\n",
      "Saved merged_homecredit_ctgan_fp.csv: 10000 rows, 44 columns\n"
     ]
    }
   ],
   "source": [
    "# Define output paths (using same directory as input for consistency)\n",
    "output_path = \"/home/frederickerleigh/Dokumente/Fintech Seminar/NewCode/FintechSeminar-Synthetic-Dataset/fintech-credit-scoring-seminar/data/processed/merged\"\n",
    "output_files = {\n",
    "    \"matched_manual_footprint.csv\": manual_fp,\n",
    "    \"matched_copula_footprint.csv\": copula_fp,\n",
    "    \"matched_ctgan_footprint.csv\": ctgan_fp,\n",
    "    \"merged_homecredit_manual_fp.csv\": merged_manual,\n",
    "    \"merged_homecredit_copula_fp.csv\": merged_copula,\n",
    "    \"merged_homecredit_ctgan_fp.csv\": merged_ctgan\n",
    "}\n",
    "\n",
    "# Save datasets and validate\n",
    "for file_name, df in output_files.items():\n",
    "    full_path = os.path.join(output_path, file_name)\n",
    "    try:\n",
    "        df.to_csv(full_path, index=False)\n",
    "        if os.path.exists(full_path):\n",
    "            saved_df = pd.read_csv(full_path)\n",
    "            print(f\"Saved {file_name}: {len(saved_df)} rows, {saved_df.shape[1]} columns\")\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Failed to save {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving {file_name}: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "#\n",
    "# All datasets have been subsampled, processed, merged, and saved successfully. Key details:\n",
    "# - **Subsampled Datasets**: `matched_manual_footprint.csv`, `matched_copula_footprint.csv`, `matched_ctgan_footprint.csv` contain only footprint variables and `DEFAULT_SYNTH`, with the same number of defaults (`{n_defaults}`) and non-defaults (`{n_nondefaults}`) as Home Credit.\n",
    "# - **Merged Datasets**: `merged_homecredit_manual_fp.csv`, `merged_homecredit_copula_fp.csv`, `merged_homecredit_ctgan_fp.csv` combine all Home Credit columns with synthetic footprint variables, aligned by TARGET/DEFAULT_SYNTH.\n",
    "# - **Default Rate**: All datasets maintain the Home Credit default rate of ~8%.\n",
    "# - **Columns**: Merged datasets include all Home Credit columns plus {len(footprint_vars)} footprint variables (plus DEFAULT_SYNTH).\n",
    "# - **Readiness**: All datasets are ready for modeling with consistent shapes, column names, and default proportions.\n",
    "#\n",
    "# The datasets are saved in `{output_path}` and can be used for downstream modeling tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
